{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfG62S6xUQe0"
   },
   "source": [
    "# COMP 6321 PROJECT - Team 16\n",
    "## Regression Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aHla1Et7UQe3"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 1. Importing Required Libraries\n",
    "\n",
    "The code block below will import all the libraries and dependencies for regression problems.\n",
    "\n",
    "**Run the code cell below** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yijqBNe7UQe5"
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.svm               # For SVC\n",
    "import sklearn.metrics           # For accuracy_score\n",
    "import sklearn.model_selection   # For GridSearchCV and RandomizedSearchCV\n",
    "import scipy\n",
    "import scipy.stats               # For reciprocal distribution\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor,RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  # Ignore sklearn deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)       # Ignore sklearn deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GCzEMGNUUQfY"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 2. Loading All Datasets\n",
    "\n",
    "The code block below will load all the datasets for regression problems.\n",
    "\n",
    "\n",
    "**Dataset Mapper**\n",
    "1. Wine Quality -> RP_1\n",
    "2. Communities and Crime -> RP_2\n",
    "3. QSAR aquatic toxicity -> RP_3\n",
    "4. Parkinson Speech -> RP_4\n",
    "5. Facebook metrics -> RP_5\n",
    "6. Bike Sharing (use hour data) -> RP_6\n",
    "7. Student Performance (use just student-por.csv if you do not know how to merge the math grades) -> RP_7\n",
    "8. Concrete Compressive Strength -> RP_8\n",
    "9. SGEMM GPU kernel performance -> RP_9\n",
    "10. Merck Molecular Activity Challenge (from Kaggle) -> RP_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vtIAO_DFUQfZ"
   },
   "outputs": [],
   "source": [
    "np.random.seed(23)\n",
    "M1Tr=[]\n",
    "M1Te=[]\n",
    "M2Tr=[]\n",
    "M2Te=[]\n",
    "MList=['SVM with RBF Kernel','SVM with Linear Kernel','Decision Tree Regressor','Random Forest Regressor','AdaBoost Regressor','Gaussian Process Regressor','Linear Regressor','Ridge Regressor']\n",
    "\n",
    "\"\"\"\n",
    "Splits the data into Features (X) and Labels (y)\n",
    "\"\"\"\n",
    "def splitData(data):\n",
    "    X = data.iloc[:,0:len(data.columns)-1]\n",
    "    y = data.iloc[:,-1]\n",
    "    return X,y\n",
    "\n",
    "\"\"\"\n",
    "Splits data into Training Set and Testing Set. \n",
    "Size Ratio of Train:Test is 70:30 \n",
    "\"\"\"\n",
    "def getTrainTestData(data):\n",
    "    X,y = splitData(data)\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y,test_size=0.3,random_state=23)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Converts categorical features by encoding\n",
    "\"\"\"\n",
    "def convertCategorical(df):\n",
    "    categorical_feature_mask = df.dtypes==object\n",
    "    categorical_cols = df.columns[categorical_feature_mask].tolist()\n",
    "    le = LabelEncoder()\n",
    "    df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "    return df;\n",
    "\n",
    "def minMax(x):\n",
    "    return pd.Series(index=['min','max'],data=[x.min(),x.max()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x0tS2M4pUQfe",
    "outputId": "6c31eaa3-005e-47c8-c683-f0c622b174ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Data Loaded Successfully.\n"
     ]
    }
   ],
   "source": [
    "# Wine Quality Data | 11 Features | 6497 Samples\n",
    "RP_1_red = pd.read_csv(\"RP_Data/winequality-red.csv\", sep=\";\",header=None,skiprows=1)\n",
    "RP_1_white = pd.read_csv(\"RP_Data/winequality-white.csv\", sep=\";\",header=None,skiprows=1)\n",
    "RP_1 = pd.concat([RP_1_red,RP_1_white])\n",
    "# print(RP_1.apply(minMax))\n",
    "RP_1_X_train, RP_1_X_test, RP_1_y_train, RP_1_y_test = getTrainTestData(RP_1)\n",
    "scaler = StandardScaler().fit(RP_1_X_train)\n",
    "RP_1_X_train = scaler.transform(RP_1_X_train)\n",
    "RP_1_X_test = scaler.transform(RP_1_X_test)\n",
    "\n",
    "# Communities and Crime Data| 127 Features | 1994 Samples \n",
    "RP_2 = pd.read_csv('RP_Data/communities.data',header=None)\n",
    "RP_2 = RP_2.drop([0, 1, 2, 3, 4], axis=1) # removed first 5 columns. non predictive\n",
    "RP_2 = RP_2.replace('?',0)\n",
    "# print(RP_2.apply(minMax))\n",
    "RP_2_X_train, RP_2_X_test, RP_2_y_train, RP_2_y_test = getTrainTestData(RP_2)\n",
    "\n",
    "\n",
    "# QSAR Aquatic Toxicity Data | 8 Features | 546 Samples\n",
    "RP_3 = pd.read_csv(\"RP_Data/qsar_aquatic_toxicity.csv\", sep=\";\",header=None)\n",
    "# print(RP_3.apply(minMax))\n",
    "RP_3_X_train, RP_3_X_test, RP_3_y_train, RP_3_y_test = getTrainTestData(RP_3)\n",
    "scaler = StandardScaler().fit(RP_3_X_train)\n",
    "RP_3_X_train = scaler.transform(RP_3_X_train)\n",
    "RP_3_X_test = scaler.transform(RP_3_X_test)\n",
    "\n",
    "\n",
    "# Parkinson Speech Data | 14 Features | 690 Samples\n",
    "RP_4 = pd.read_csv(\"RP_Data/parkinsons_train_data.txt\", sep=\",\",header=None)\n",
    "RP_4 = RP_4.drop([28], axis=1) # removed last column. categorical output\n",
    "# print(RP_4_train.shape)\n",
    "# print(RP_4_test.shape)\n",
    "# print(RP_4_train[28].nunique())\n",
    "# print(RP_4_test[27].nunique())\n",
    "RP_4_X_train, RP_4_X_test, RP_4_y_train, RP_4_y_test = getTrainTestData(RP_4)\n",
    "scaler = StandardScaler().fit(RP_4_X_train)\n",
    "RP_4_X_train = scaler.transform(RP_4_X_train)\n",
    "RP_4_X_test = scaler.transform(RP_4_X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Facebook Data | 18 Features | 500 Samples \n",
    "RP_5 = pd.read_csv(\"RP_Data/dataset_Facebook.csv\", sep=\";\")\n",
    "RP_5 = convertCategorical(RP_5)\n",
    "RP_5  = RP_5.fillna(RP_5.mean())\n",
    "# print(RP_5.apply(minMax))\n",
    "RP_5_X_train, RP_5_X_test, RP_5_y_train, RP_5_y_test = getTrainTestData(RP_5)\n",
    "scaler = StandardScaler().fit(RP_5_X_train)\n",
    "RP_5_X_train = scaler.transform(RP_5_X_train)\n",
    "RP_5_X_test = scaler.transform(RP_5_X_test)\n",
    "\n",
    "\n",
    "# Bike Sharing Hours Data | 16 Features | 17379 Samples \n",
    "RP_6 = pd.read_csv(\"RP_Data/hour.csv\", sep=\",\")\n",
    "RP_6 = RP_6.drop(['instant'], axis=1) # removed second last column. non predictive\n",
    "RP_6 = convertCategorical(RP_6)\n",
    "# print(RP_6.apply(minMax))\n",
    "RP_6_X_train, RP_6_X_test, RP_6_y_train, RP_6_y_test = getTrainTestData(RP_6)\n",
    "scaler = StandardScaler().fit(RP_6_X_train)\n",
    "RP_6_X_train = scaler.transform(RP_6_X_train)\n",
    "RP_6_X_test = scaler.transform(RP_6_X_test)\n",
    "\n",
    "\n",
    "# Student Performance Data | 32 Features | 4934964982 Samples\n",
    "RP_7 = pd.read_csv(\"RP_Data/student-por.csv\", sep=\";\")\n",
    "RP_7 = convertCategorical(RP_7)\n",
    "# print(RP_7.apply(minMax))\n",
    "RP_7_X_train, RP_7_X_test, RP_7_y_train, RP_7_y_test = getTrainTestData(RP_7)\n",
    "\n",
    "\n",
    "# Concrete Data | 8 Features | 1030 Samples\n",
    "RP_8 =  pd.read_excel (r'RP_Data/Concrete_Data.xls',skiprows=1,header=None)\n",
    "# print(RP_8.apply(minMax))\n",
    "RP_8_X_train, RP_8_X_test, RP_8_y_train, RP_8_y_test = getTrainTestData(RP_8)\n",
    "scaler = StandardScaler().fit(RP_8_X_train)\n",
    "RP_8_X_train = scaler.transform(RP_8_X_train)\n",
    "RP_8_X_test = scaler.transform(RP_8_X_test)\n",
    "\n",
    "\n",
    "# SGEMM GPU kernel performance Data | 14 Features | 241600 Samples \n",
    "RP_9 = pd.read_csv(\"RP_Data/sgemm_product.csv\", sep=\",\")\n",
    "RP_9['Run (ms)'] = RP_9.iloc[:, -4:].sum(axis=1)/4 #add column of average run of 4 runs\n",
    "RP_9 = RP_9.drop(['Run1 (ms)','Run2 (ms)','Run3 (ms)','Run4 (ms)'], axis = 1)  #drop 4 runs column\n",
    "# print(RP_9.apply(minMax))\n",
    "RP_9_X_train, RP_9_X_test, RP_9_y_train, RP_9_y_test = getTrainTestData(RP_9)\n",
    "scaler = StandardScaler().fit(RP_9_X_train)\n",
    "RP_9_X_train = scaler.transform(RP_9_X_train)\n",
    "RP_9_X_test = scaler.transform(RP_9_X_test)\n",
    "\n",
    "\n",
    "#Merck Molecular Dataset 1 | 5877 Features | 8716 Samples \n",
    "npzfile = np.load('RP_Data/File1.npz')\n",
    "RP_101_X = npzfile['arr_0']\n",
    "RP_101_y = npzfile['arr_1']\n",
    "RP_101_X_train, RP_101_X_test, RP_101_y_train, RP_101_y_test = sklearn.model_selection.train_test_split(RP_101_X,RP_101_y,test_size=0.3,random_state=23)\n",
    "\n",
    "\n",
    "#Merck Molecular Dataset 2 | 4306 Features | w Samples \n",
    "npzfile = np.load('RP_Data/File2.npz')\n",
    "RP_102_X = npzfile['arr_0']\n",
    "RP_102_y = npzfile['arr_1']\n",
    "RP_102_X_train, RP_102_X_test, RP_102_y_train, RP_102_y_test = sklearn.model_selection.train_test_split(RP_102_X,RP_102_y,test_size=0.3,random_state=23)\n",
    "\n",
    "print('Regression Data Loaded Successfully.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
