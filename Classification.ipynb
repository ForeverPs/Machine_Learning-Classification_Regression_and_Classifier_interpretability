{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UA8VcLZFk9pr"
   },
   "source": [
    "# COMP 6321 PROJECT - Team 16\n",
    "## Clasification Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22m39mnbk9pv"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 1. Importing Required Libraries\n",
    "\n",
    "The code block below will load all the datasets for classification problems.\n",
    "\n",
    "**Run the code cell below** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0Wvx7rTk9pw"
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.svm               # For SVC\n",
    "import sklearn.model_selection   # For GridSearchCV and RandomizedSearchCV\n",
    "import scipy\n",
    "import scipy.stats               # For reciprocal distribution\n",
    "import warnings\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, recall_score, precision_score,accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler,MinMaxScaler\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  # Ignore sklearn deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)       # Ignore sklearn deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cy_ewTcDk9p2"
   },
   "source": [
    "<div style=\"border-bottom: 3px solid black; margin-bottom:5px\"></div>\n",
    "<div style=\"border-bottom: 3px solid black\"></div>\n",
    "\n",
    "# 2. Loading All Datasets\n",
    "\n",
    "The code block below will load all the datasets for classification problems.\n",
    "\n",
    "\n",
    "**Dataset Mapper**\n",
    "1. Diabetic Retinopathy -> CP_1\n",
    "2. Default of credit card clients -> CP_2\n",
    "3. Breast Cancer Wisconsin -> CP_3\n",
    "4. Statlog (Australian credit approval) -> CP_4\n",
    "5. Statlog (German credit data) -> CP_5\n",
    "6. Steel Plates Faults -> CP_6\n",
    "7. Adult -> CP_7\n",
    "8. Yeast -> CP_8\n",
    "9. Thoracic Surgery Data -> CP_9\n",
    "10. Seismic-Bumps -> CP_10\n",
    "\n",
    "**Run the code cell below to load the data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CXU178Vmk9p3"
   },
   "outputs": [],
   "source": [
    "np.random.seed(23)\n",
    "\"\"\"\n",
    "Splits the data into Features (X) and Labels (y)\n",
    "\"\"\"\n",
    "def splitData(data):\n",
    "    X = data.iloc[:,:len(data.columns)-1]\n",
    "    y = data.iloc[:,-1]\n",
    "    #print(y.value_counts())\n",
    "    return X,y\n",
    "\n",
    "\"\"\"\n",
    "Splits data into Training Set and Testing Set. \n",
    "Size Ratio of Train:Test is 80:20 \n",
    "\"\"\"\n",
    "def getTrainTestData(data):\n",
    "    X,y = splitData(data)\n",
    "    #if type(y[0]) is int:\n",
    "    y = y.astype(int)\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Converts categorical features by encoding\n",
    "\"\"\"\n",
    "def convertCategorical(df):\n",
    "    categorical_feature_mask = df.dtypes==object\n",
    "    categorical_cols = df.columns[categorical_feature_mask].tolist()\n",
    "    le = LabelEncoder()\n",
    "    df[categorical_cols] = df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
    "    return df;\n",
    "\n",
    "\"\"\"\n",
    "Checks for ? in the data frame\n",
    "\"\"\"\n",
    "def check(df):\n",
    "    dic = {}\n",
    "    lst = df.columns[df.isin([' ?']).any()]\n",
    "    for x in lst:\n",
    "        dic = df[x].value_counts().to_dict()\n",
    "        key_list = list(dic.keys()) \n",
    "        val_list = list(dic.values())\n",
    "        maxi=key_list[val_list.index(max(val_list))]\n",
    "        df[x]=df[x].replace(' ?', maxi)\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Returns min and max value of every column\n",
    "\"\"\"\n",
    "def minMax(x):\n",
    "    return pd.Series(index=['min','max'],data=[x.min(),x.max()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 896
    },
    "colab_type": "code",
    "id": "CeXxdcr-k9p7",
    "outputId": "22c5dd3a-11d4-42ce-bdf0-ecd245d1de07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance count for diabetic retinopathy data set\n",
      "b'1'    611\n",
      "b'0'    540\n",
      "Name: Class, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for default credit card clients data set\n",
      "0    23364\n",
      "1     6636\n",
      "Name: 23, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for breast cancer data set\n",
      "0    458\n",
      "1    241\n",
      "Name: 10, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for australian credit approval data set\n",
      "0    383\n",
      "1    307\n",
      "Name: 14, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for german credit data set\n",
      "1    700\n",
      "2    300\n",
      "Name: 24, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for steel plates faults data set\n",
      "0    1268\n",
      "1     673\n",
      "Name: 33, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for adult data set\n",
      "0    24720\n",
      "1     7841\n",
      "Name: 14, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for yeast data set\n",
      "0    463\n",
      "7    429\n",
      "6    244\n",
      "5    163\n",
      "4     51\n",
      "3     44\n",
      "2     35\n",
      "9     30\n",
      "8     20\n",
      "1      5\n",
      "Name: 9, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Class balance count for thoracic surgery data set\n",
      "0    400\n",
      "1     70\n",
      "Name: 16, dtype: int64\n",
      "\n",
      "------------------------------------------------------------\n",
      "Class balance count for seismic bumps data set\n",
      "0    2414\n",
      "1     170\n",
      "Name: 15, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Classification Data Loaded Successfully.\n"
     ]
    }
   ],
   "source": [
    "# Diabetic Retinopathy Data | 19 Features | 1151 Samples\n",
    "CP_1 = arff.loadarff('CP_Data/messidor_features.arff')\n",
    "CP_1 = pd.DataFrame(CP_1[0])\n",
    "print('Class balance count for diabetic retinopathy data set')\n",
    "print(CP_1.iloc[:,-1].value_counts())\n",
    "CP_1_X_train, CP_1_X_test, CP_1_y_train, CP_1_y_test = getTrainTestData(CP_1)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "\n",
    "# Default of Credit Card Clients Data| 23 Features | 30000 Samples\n",
    "CP_2 = pd.read_excel ('CP_Data/credit.xls',header=None,skiprows=2)\n",
    "CP_2 = CP_2.drop(0, 1)\n",
    "CP_2.columns = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23]\n",
    "print('Class balance count for default credit card clients data set')\n",
    "print(CP_2.iloc[:,-1].value_counts())\n",
    "CP_2_X_train, CP_2_X_test, CP_2_y_train, CP_2_y_test = getTrainTestData(CP_2)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Breast Cancer Wisconsin Data | 10 Features | 699 Samples\n",
    "CP_3 = pd.read_csv(\"CP_Data/breast-cancer-wisconsin.data\", sep=\",\",header=None)\n",
    "CP_3=CP_3.replace('?', 5.5)\n",
    "#print(CP_3cp[6].value_counts())\n",
    "CP_3[6]=CP_3[6].astype(int)\n",
    "CP_3[10]= CP_3[10].replace(2,0)\n",
    "CP_3[10]= CP_3[10].replace(4,1)\n",
    "print('Class balance count for breast cancer data set')\n",
    "print(CP_3.iloc[:,-1].value_counts())\n",
    "CP_3_X_train, CP_3_X_test, CP_3_y_train, CP_3_y_test = getTrainTestData(CP_3)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Australian Credit Approval Data | 14 Features | 690 Samples\n",
    "CP_4 = pd.read_csv(\"CP_Data/australian.dat\", sep=\"\\s+\",header=None)\n",
    "print('Class balance count for australian credit approval data set')\n",
    "print(CP_4.iloc[:,-1].value_counts())\n",
    "CP_4_X_train, CP_4_X_test, CP_4_y_train, CP_4_y_test = getTrainTestData(CP_4)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# German Credit Data | 24 Features | 1000 Samples\n",
    "CP_5 = pd.read_csv(\"CP_Data/german.data-numeric\", sep=\"\\s+\",header=None)\n",
    "print('Class balance count for german credit data set')\n",
    "print(CP_5.iloc[:,-1].value_counts())\n",
    "CP_5_X_train, CP_5_X_test, CP_5_y_train, CP_5_y_test = getTrainTestData(CP_5)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Steel Plates Faults Data | 33 Features | 1941 Samples\n",
    "CP_6 = pd.read_csv(\"CP_Data/Faults.NNA\", sep=\"\\s+\",header=None)\n",
    "print('Class balance count for steel plates faults data set')\n",
    "print(CP_6.iloc[:,-1].value_counts())\n",
    "CP_6_X_train, CP_6_X_test, CP_6_y_train, CP_6_y_test = getTrainTestData(CP_6)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "#Adult Data | 14 Features | 49382 Samples\n",
    "CP_7 = pd.read_csv(\"CP_Data/adult.data\", sep=\",\",header=None)\n",
    "if(' ?' in CP_7.values):\n",
    "    CP_7=check(CP_7)\n",
    "CP_7= convertCategorical(CP_7)\n",
    "print('Class balance count for adult data set')\n",
    "print(CP_7.iloc[:,-1].value_counts())\n",
    "CP_7_X_train, CP_7_y_train = splitData(CP_7)\n",
    "CP_7_test = pd.read_csv(\"CP_Data/adult.test\", sep=\",\",header=None,skiprows=1)\n",
    "if(' ?' in CP_7_test.values):\n",
    "    CP_7_test=check(CP_7_test)\n",
    "CP_7_test= convertCategorical(CP_7_test)\n",
    "CP_7_X_test, CP_7_y_test = splitData(CP_7_test)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "# Yeast Data | 9 Features | 1484 Samples\n",
    "CP_8 = pd.read_csv(\"CP_Data/yeast.data\", sep=\"\\s+\",header=None)\n",
    "CP_8= convertCategorical(CP_8)\n",
    "X1,y1 = splitData(CP_8)\n",
    "print('Class balance count for yeast data set')\n",
    "print(CP_8.iloc[:,-1].value_counts())\n",
    "CP_8_X_train, CP_8_X_test, CP_8_y_train, CP_8_y_test = sklearn.model_selection.train_test_split(X1,y1,test_size=0.2,random_state=0)\n",
    "#CP_8_X_train, CP_8_X_test, CP_8_y_train, CP_8_y_test = getTrainTestData(CP_8)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "\n",
    "# Thoracic Surgery Data | 16 Features | 470 Samples\n",
    "CP_9 = arff.loadarff('CP_Data/ThoraricSurgery.arff')\n",
    "CP_9 = pd.DataFrame(CP_9[0])\n",
    "CP_9.columns = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "CP_9= convertCategorical(CP_9)\n",
    "print('Class balance count for thoracic surgery data set')\n",
    "print(CP_9.iloc[:,-1].value_counts())\n",
    "CP_9_X_train, CP_9_X_test, CP_9_y_train, CP_9_y_test = getTrainTestData(CP_9)\n",
    "print()\n",
    "#X2,y2 = splitData(CP_9)\n",
    "#CP_9_X_train, CP_9_X_test, CP_9_y_train, CP_9_y_test = sklearn.model_selection.train_test_split(X2,y2,test_size=0.2,random_state=0)\n",
    "#CP_9_X_train, CP_9_X_test, CP_9_y_train, CP_9_y_test = getTrainTestData(CP_9)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "\n",
    "# Seismic-Bumps | 18 Features | 2584 Samples\n",
    "# delete column 13 14 15 bcs of one same value\n",
    "CP_10 = arff.loadarff('CP_Data/seismic-bumps.arff')\n",
    "CP_10 = pd.DataFrame(CP_10[0])\n",
    "#plt.matshow(CP_101.corr())\n",
    "#plt.show()\n",
    "CP_10.columns = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
    "del CP_10[13]\n",
    "del CP_10[14]\n",
    "del CP_10[15]\n",
    "CP_10.columns = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "CP_10= convertCategorical(CP_10)\n",
    "print('Class balance count for seismic bumps data set')\n",
    "print(CP_10.iloc[:,-1].value_counts())\n",
    "CP_10_X_train, CP_10_X_test, CP_10_y_train, CP_10_y_test = getTrainTestData(CP_10)\n",
    "print('------------------------------------------------------------')\n",
    "\n",
    "print('Classification Data Loaded Successfully.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ClassificationNEW.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
